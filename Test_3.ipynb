{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janta_Hack Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing important Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "pd.options.display.max_columns = 50 \n",
    "pd.get_option('display.max_rows') \n",
    "pd.set_option('display.max_rows',None) \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop \n",
    "\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Images.\n",
    "image_path = 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data sets.\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_vc2kHdQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1646 entries, 0 to 1645\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   image_names       1646 non-null   object\n",
      " 1   emergency_or_not  1646 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 706 entries, 0 to 705\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   image_names  706 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1764.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1356.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  emergency_or_not\n",
       "0    1503.jpg                 0\n",
       "1    1420.jpg                 0\n",
       "2    1764.jpg                 0\n",
       "3    1356.jpg                 0\n",
       "4    1117.jpg                 0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>668.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2082.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>808.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names\n",
       "0    1960.jpg\n",
       "1     668.jpg\n",
       "2    2082.jpg\n",
       "3     808.jpg\n",
       "4    1907.jpg"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1646</td>\n",
       "      <td>1646.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>569.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.492651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_names  emergency_or_not\n",
       "count         1646       1646.000000\n",
       "unique        1646               NaN\n",
       "top        569.jpg               NaN\n",
       "freq             1               NaN\n",
       "mean           NaN          0.413730\n",
       "std            NaN          0.492651\n",
       "min            NaN          0.000000\n",
       "25%            NaN          0.000000\n",
       "50%            NaN          0.000000\n",
       "75%            NaN          1.000000\n",
       "max            NaN          1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>211.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_names\n",
       "count          706\n",
       "unique         706\n",
       "top        211.jpg\n",
       "freq             1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe(include ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the images from path using CSV names.\n",
    "def get_images_list(path):\n",
    "    image_list = []\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        image_list.append(img) \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2352/2352 [00:00<00:00, 624288.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use function to get the list \n",
    "image_list = get_images_list(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.jpg',\n",
       " '1.jpg',\n",
       " '10.jpg',\n",
       " '100.jpg',\n",
       " '1000.jpg',\n",
       " '1001.jpg',\n",
       " '1002.jpg',\n",
       " '1003.jpg',\n",
       " '1004.jpg',\n",
       " '1005.jpg',\n",
       " '1006.jpg',\n",
       " '1007.jpg',\n",
       " '1008.jpg',\n",
       " '1009.jpg',\n",
       " '101.jpg',\n",
       " '1010.jpg',\n",
       " '1011.jpg',\n",
       " '1012.jpg',\n",
       " '1013.jpg',\n",
       " '1014.jpg',\n",
       " '1015.jpg',\n",
       " '1016.jpg',\n",
       " '1017.jpg',\n",
       " '1018.jpg',\n",
       " '1019.jpg',\n",
       " '102.jpg',\n",
       " '1020.jpg',\n",
       " '1021.jpg',\n",
       " '1022.jpg',\n",
       " '1023.jpg',\n",
       " '1024.jpg',\n",
       " '1025.jpg',\n",
       " '1026.jpg',\n",
       " '1027.jpg',\n",
       " '1028.jpg',\n",
       " '1029.jpg',\n",
       " '103.jpg',\n",
       " '1030.jpg',\n",
       " '1031.jpg',\n",
       " '1032.jpg',\n",
       " '1033.jpg',\n",
       " '1034.jpg',\n",
       " '1035.jpg',\n",
       " '1036.jpg',\n",
       " '1037.jpg',\n",
       " '1038.jpg',\n",
       " '1039.jpg',\n",
       " '104.jpg',\n",
       " '1040.jpg',\n",
       " '1041.jpg',\n",
       " '1042.jpg',\n",
       " '1043.jpg',\n",
       " '1044.jpg',\n",
       " '1045.jpg',\n",
       " '1046.jpg',\n",
       " '1047.jpg',\n",
       " '1048.jpg',\n",
       " '1049.jpg',\n",
       " '105.jpg',\n",
       " '1050.jpg',\n",
       " '1051.jpg',\n",
       " '1052.jpg',\n",
       " '1053.jpg',\n",
       " '1054.jpg',\n",
       " '1055.jpg',\n",
       " '1056.jpg',\n",
       " '1057.jpg',\n",
       " '1058.jpg',\n",
       " '1059.jpg',\n",
       " '106.jpg',\n",
       " '1060.jpg',\n",
       " '1061.jpg',\n",
       " '1062.jpg',\n",
       " '1063.jpg',\n",
       " '1064.jpg',\n",
       " '1065.jpg',\n",
       " '1066.jpg',\n",
       " '1067.jpg',\n",
       " '1068.jpg',\n",
       " '1069.jpg',\n",
       " '107.jpg',\n",
       " '1070.jpg',\n",
       " '1071.jpg',\n",
       " '1072.jpg',\n",
       " '1073.jpg',\n",
       " '1074.jpg',\n",
       " '1075.jpg',\n",
       " '1076.jpg',\n",
       " '1077.jpg',\n",
       " '1078.jpg',\n",
       " '1079.jpg',\n",
       " '108.jpg',\n",
       " '1080.jpg',\n",
       " '1081.jpg',\n",
       " '1082.jpg',\n",
       " '1083.jpg',\n",
       " '1084.jpg',\n",
       " '1085.jpg',\n",
       " '1086.jpg',\n",
       " '1087.jpg',\n",
       " '1088.jpg',\n",
       " '1089.jpg',\n",
       " '109.jpg',\n",
       " '1090.jpg',\n",
       " '1091.jpg',\n",
       " '1092.jpg',\n",
       " '1093.jpg',\n",
       " '1094.jpg',\n",
       " '1095.jpg',\n",
       " '1096.jpg',\n",
       " '1097.jpg',\n",
       " '1098.jpg',\n",
       " '1099.jpg',\n",
       " '11.jpg',\n",
       " '110.jpg',\n",
       " '1100.jpg',\n",
       " '1101.jpg',\n",
       " '1102.jpg',\n",
       " '1103.jpg',\n",
       " '1104.jpg',\n",
       " '1105.jpg',\n",
       " '1106.jpg',\n",
       " '1107.jpg',\n",
       " '1108.jpg',\n",
       " '1109.jpg',\n",
       " '111.jpg',\n",
       " '1110.jpg',\n",
       " '1111.jpg',\n",
       " '1112.jpg',\n",
       " '1113.jpg',\n",
       " '1114.jpg',\n",
       " '1115.jpg',\n",
       " '1116.jpg',\n",
       " '1117.jpg',\n",
       " '1118.jpg',\n",
       " '1119.jpg',\n",
       " '112.jpg',\n",
       " '1120.jpg',\n",
       " '1121.jpg',\n",
       " '1122.jpg',\n",
       " '1123.jpg',\n",
       " '1124.jpg',\n",
       " '1125.jpg',\n",
       " '1126.jpg',\n",
       " '1127.jpg',\n",
       " '1128.jpg',\n",
       " '1129.jpg',\n",
       " '113.jpg',\n",
       " '1130.jpg',\n",
       " '1131.jpg',\n",
       " '1132.jpg',\n",
       " '1133.jpg',\n",
       " '1134.jpg',\n",
       " '1135.jpg',\n",
       " '1136.jpg',\n",
       " '1137.jpg',\n",
       " '1138.jpg',\n",
       " '1139.jpg',\n",
       " '114.jpg',\n",
       " '1140.jpg',\n",
       " '1141.jpg',\n",
       " '1142.jpg',\n",
       " '1143.jpg',\n",
       " '1144.jpg',\n",
       " '1145.jpg',\n",
       " '1146.jpg',\n",
       " '1147.jpg',\n",
       " '1148.jpg',\n",
       " '1149.jpg',\n",
       " '115.jpg',\n",
       " '1150.jpg',\n",
       " '1151.jpg',\n",
       " '1152.jpg',\n",
       " '1153.jpg',\n",
       " '1154.jpg',\n",
       " '1155.jpg',\n",
       " '1156.jpg',\n",
       " '1157.jpg',\n",
       " '1158.jpg',\n",
       " '1159.jpg',\n",
       " '116.jpg',\n",
       " '1160.jpg',\n",
       " '1161.jpg',\n",
       " '1162.jpg',\n",
       " '1163.jpg',\n",
       " '1164.jpg',\n",
       " '1165.jpg',\n",
       " '1166.jpg',\n",
       " '1167.jpg',\n",
       " '1168.jpg',\n",
       " '1169.jpg',\n",
       " '117.jpg',\n",
       " '1170.jpg',\n",
       " '1171.jpg',\n",
       " '1172.jpg',\n",
       " '1173.jpg',\n",
       " '1174.jpg',\n",
       " '1175.jpg',\n",
       " '1176.jpg',\n",
       " '1177.jpg',\n",
       " '1178.jpg',\n",
       " '1179.jpg',\n",
       " '118.jpg',\n",
       " '1180.jpg',\n",
       " '1181.jpg',\n",
       " '1182.jpg',\n",
       " '1183.jpg',\n",
       " '1184.jpg',\n",
       " '1185.jpg',\n",
       " '1186.jpg',\n",
       " '1187.jpg',\n",
       " '1188.jpg',\n",
       " '1189.jpg',\n",
       " '119.jpg',\n",
       " '1190.jpg',\n",
       " '1191.jpg',\n",
       " '1192.jpg',\n",
       " '1193.jpg',\n",
       " '1194.jpg',\n",
       " '1195.jpg',\n",
       " '1196.jpg',\n",
       " '1197.jpg',\n",
       " '1198.jpg',\n",
       " '1199.jpg',\n",
       " '12.jpg',\n",
       " '120.jpg',\n",
       " '1200.jpg',\n",
       " '1201.jpg',\n",
       " '1202.jpg',\n",
       " '1203.jpg',\n",
       " '1204.jpg',\n",
       " '1205.jpg',\n",
       " '1206.jpg',\n",
       " '1207.jpg',\n",
       " '1208.jpg',\n",
       " '1209.jpg',\n",
       " '121.jpg',\n",
       " '1210.jpg',\n",
       " '1211.jpg',\n",
       " '1212.jpg',\n",
       " '1213.jpg',\n",
       " '1214.jpg',\n",
       " '1215.jpg',\n",
       " '1216.jpg',\n",
       " '1217.jpg',\n",
       " '1218.jpg',\n",
       " '1219.jpg',\n",
       " '122.jpg',\n",
       " '1220.jpg',\n",
       " '1221.jpg',\n",
       " '1222.jpg',\n",
       " '1223.jpg',\n",
       " '1224.jpg',\n",
       " '1225.jpg',\n",
       " '1226.jpg',\n",
       " '1227.jpg',\n",
       " '1228.jpg',\n",
       " '1229.jpg',\n",
       " '123.jpg',\n",
       " '1230.jpg',\n",
       " '1231.jpg',\n",
       " '1232.jpg',\n",
       " '1233.jpg',\n",
       " '1234.jpg',\n",
       " '1235.jpg',\n",
       " '1236.jpg',\n",
       " '1237.jpg',\n",
       " '1238.jpg',\n",
       " '1239.jpg',\n",
       " '124.jpg',\n",
       " '1240.jpg',\n",
       " '1241.jpg',\n",
       " '1242.jpg',\n",
       " '1243.jpg',\n",
       " '1244.jpg',\n",
       " '1245.jpg',\n",
       " '1246.jpg',\n",
       " '1247.jpg',\n",
       " '1248.jpg',\n",
       " '1249.jpg',\n",
       " '125.jpg',\n",
       " '1250.jpg',\n",
       " '1251.jpg',\n",
       " '1252.jpg',\n",
       " '1253.jpg',\n",
       " '1254.jpg',\n",
       " '1255.jpg',\n",
       " '1256.jpg',\n",
       " '1257.jpg',\n",
       " '1258.jpg',\n",
       " '1259.jpg',\n",
       " '126.jpg',\n",
       " '1260.jpg',\n",
       " '1261.jpg',\n",
       " '1262.jpg',\n",
       " '1263.jpg',\n",
       " '1264.jpg',\n",
       " '1265.jpg',\n",
       " '1266.jpg',\n",
       " '1267.jpg',\n",
       " '1268.jpg',\n",
       " '1269.jpg',\n",
       " '127.jpg',\n",
       " '1270.jpg',\n",
       " '1271.jpg',\n",
       " '1272.jpg',\n",
       " '1273.jpg',\n",
       " '1274.jpg',\n",
       " '1275.jpg',\n",
       " '1276.jpg',\n",
       " '1277.jpg',\n",
       " '1278.jpg',\n",
       " '1279.jpg',\n",
       " '128.jpg',\n",
       " '1280.jpg',\n",
       " '1281.jpg',\n",
       " '1282.jpg',\n",
       " '1283.jpg',\n",
       " '1284.jpg',\n",
       " '1285.jpg',\n",
       " '1286.jpg',\n",
       " '1287.jpg',\n",
       " '1288.jpg',\n",
       " '1289.jpg',\n",
       " '129.jpg',\n",
       " '1290.jpg',\n",
       " '1291.jpg',\n",
       " '1292.jpg',\n",
       " '1293.jpg',\n",
       " '1294.jpg',\n",
       " '1295.jpg',\n",
       " '1296.jpg',\n",
       " '1297.jpg',\n",
       " '1298.jpg',\n",
       " '1299.jpg',\n",
       " '13.jpg',\n",
       " '130.jpg',\n",
       " '1300.jpg',\n",
       " '1301.jpg',\n",
       " '1302.jpg',\n",
       " '1303.jpg',\n",
       " '1304.jpg',\n",
       " '1305.jpg',\n",
       " '1306.jpg',\n",
       " '1307.jpg',\n",
       " '1308.jpg',\n",
       " '1309.jpg',\n",
       " '131.jpg',\n",
       " '1310.jpg',\n",
       " '1311.jpg',\n",
       " '1312.jpg',\n",
       " '1313.jpg',\n",
       " '1314.jpg',\n",
       " '1315.jpg',\n",
       " '1316.jpg',\n",
       " '1317.jpg',\n",
       " '1318.jpg',\n",
       " '1319.jpg',\n",
       " '132.jpg',\n",
       " '1320.jpg',\n",
       " '1321.jpg',\n",
       " '1322.jpg',\n",
       " '1323.jpg',\n",
       " '1324.jpg',\n",
       " '1325.jpg',\n",
       " '1326.jpg',\n",
       " '1327.jpg',\n",
       " '1328.jpg',\n",
       " '1329.jpg',\n",
       " '133.jpg',\n",
       " '1330.jpg',\n",
       " '1331.jpg',\n",
       " '1332.jpg',\n",
       " '1333.jpg',\n",
       " '1334.jpg',\n",
       " '1335.jpg',\n",
       " '1336.jpg',\n",
       " '1337.jpg',\n",
       " '1338.jpg',\n",
       " '1339.jpg',\n",
       " '134.jpg',\n",
       " '1340.jpg',\n",
       " '1341.jpg',\n",
       " '1342.jpg',\n",
       " '1343.jpg',\n",
       " '1344.jpg',\n",
       " '1345.jpg',\n",
       " '1346.jpg',\n",
       " '1347.jpg',\n",
       " '1348.jpg',\n",
       " '1349.jpg',\n",
       " '135.jpg',\n",
       " '1350.jpg',\n",
       " '1351.jpg',\n",
       " '1352.jpg',\n",
       " '1353.jpg',\n",
       " '1354.jpg',\n",
       " '1355.jpg',\n",
       " '1356.jpg',\n",
       " '1357.jpg',\n",
       " '1358.jpg',\n",
       " '1359.jpg',\n",
       " '136.jpg',\n",
       " '1360.jpg',\n",
       " '1361.jpg',\n",
       " '1362.jpg',\n",
       " '1363.jpg',\n",
       " '1364.jpg',\n",
       " '1365.jpg',\n",
       " '1366.jpg',\n",
       " '1367.jpg',\n",
       " '1368.jpg',\n",
       " '1369.jpg',\n",
       " '137.jpg',\n",
       " '1370.jpg',\n",
       " '1371.jpg',\n",
       " '1372.jpg',\n",
       " '1373.jpg',\n",
       " '1374.jpg',\n",
       " '1375.jpg',\n",
       " '1376.jpg',\n",
       " '1377.jpg',\n",
       " '1378.jpg',\n",
       " '1379.jpg',\n",
       " '138.jpg',\n",
       " '1380.jpg',\n",
       " '1381.jpg',\n",
       " '1382.jpg',\n",
       " '1383.jpg',\n",
       " '1384.jpg',\n",
       " '1385.jpg',\n",
       " '1386.jpg',\n",
       " '1387.jpg',\n",
       " '1388.jpg',\n",
       " '1389.jpg',\n",
       " '139.jpg',\n",
       " '1390.jpg',\n",
       " '1391.jpg',\n",
       " '1392.jpg',\n",
       " '1393.jpg',\n",
       " '1394.jpg',\n",
       " '1395.jpg',\n",
       " '1396.jpg',\n",
       " '1397.jpg',\n",
       " '1398.jpg',\n",
       " '1399.jpg',\n",
       " '14.jpg',\n",
       " '140.jpg',\n",
       " '1400.jpg',\n",
       " '1401.jpg',\n",
       " '1402.jpg',\n",
       " '1403.jpg',\n",
       " '1404.jpg',\n",
       " '1405.jpg',\n",
       " '1406.jpg',\n",
       " '1407.jpg',\n",
       " '1408.jpg',\n",
       " '1409.jpg',\n",
       " '141.jpg',\n",
       " '1410.jpg',\n",
       " '1411.jpg',\n",
       " '1412.jpg',\n",
       " '1413.jpg',\n",
       " '1414.jpg',\n",
       " '1415.jpg',\n",
       " '1416.jpg',\n",
       " '1417.jpg',\n",
       " '1418.jpg',\n",
       " '1419.jpg',\n",
       " '142.jpg',\n",
       " '1420.jpg',\n",
       " '1421.jpg',\n",
       " '1422.jpg',\n",
       " '1423.jpg',\n",
       " '1424.jpg',\n",
       " '1425.jpg',\n",
       " '1426.jpg',\n",
       " '1427.jpg',\n",
       " '1428.jpg',\n",
       " '1429.jpg',\n",
       " '143.jpg',\n",
       " '1430.jpg',\n",
       " '1431.jpg',\n",
       " '1432.jpg',\n",
       " '1433.jpg',\n",
       " '1434.jpg',\n",
       " '1435.jpg',\n",
       " '1436.jpg',\n",
       " '1437.jpg',\n",
       " '1438.jpg',\n",
       " '1439.jpg',\n",
       " '144.jpg',\n",
       " '1440.jpg',\n",
       " '1441.jpg',\n",
       " '1442.jpg',\n",
       " '1443.jpg',\n",
       " '1444.jpg',\n",
       " '1445.jpg',\n",
       " '1446.jpg',\n",
       " '1447.jpg',\n",
       " '1448.jpg',\n",
       " '1449.jpg',\n",
       " '145.jpg',\n",
       " '1450.jpg',\n",
       " '1451.jpg',\n",
       " '1452.jpg',\n",
       " '1453.jpg',\n",
       " '1454.jpg',\n",
       " '1455.jpg',\n",
       " '1456.jpg',\n",
       " '1457.jpg',\n",
       " '1458.jpg',\n",
       " '1459.jpg',\n",
       " '146.jpg',\n",
       " '1460.jpg',\n",
       " '1461.jpg',\n",
       " '1462.jpg',\n",
       " '1463.jpg',\n",
       " '1464.jpg',\n",
       " '1465.jpg',\n",
       " '1466.jpg',\n",
       " '1467.jpg',\n",
       " '1468.jpg',\n",
       " '1469.jpg',\n",
       " '147.jpg',\n",
       " '1470.jpg',\n",
       " '1471.jpg',\n",
       " '1472.jpg',\n",
       " '1473.jpg',\n",
       " '1474.jpg',\n",
       " '1475.jpg',\n",
       " '1476.jpg',\n",
       " '1477.jpg',\n",
       " '1478.jpg',\n",
       " '1479.jpg',\n",
       " '148.jpg',\n",
       " '1480.jpg',\n",
       " '1481.jpg',\n",
       " '1482.jpg',\n",
       " '1483.jpg',\n",
       " '1484.jpg',\n",
       " '1485.jpg',\n",
       " '1486.jpg',\n",
       " '1487.jpg',\n",
       " '1488.jpg',\n",
       " '1489.jpg',\n",
       " '149.jpg',\n",
       " '1490.jpg',\n",
       " '1491.jpg',\n",
       " '1492.jpg',\n",
       " '1493.jpg',\n",
       " '1494.jpg',\n",
       " '1495.jpg',\n",
       " '1496.jpg',\n",
       " '1497.jpg',\n",
       " '1498.jpg',\n",
       " '1499.jpg',\n",
       " '15.jpg',\n",
       " '150.jpg',\n",
       " '1500.jpg',\n",
       " '1501.jpg',\n",
       " '1502.jpg',\n",
       " '1503.jpg',\n",
       " '1504.jpg',\n",
       " '1505.jpg',\n",
       " '1506.jpg',\n",
       " '1507.jpg',\n",
       " '1508.jpg',\n",
       " '1509.jpg',\n",
       " '151.jpg',\n",
       " '1510.jpg',\n",
       " '1511.jpg',\n",
       " '1512.jpg',\n",
       " '1513.jpg',\n",
       " '1514.jpg',\n",
       " '1515.jpg',\n",
       " '1516.jpg',\n",
       " '1517.jpg',\n",
       " '1518.jpg',\n",
       " '1519.jpg',\n",
       " '152.jpg',\n",
       " '1520.jpg',\n",
       " '1521.jpg',\n",
       " '1522.jpg',\n",
       " '1523.jpg',\n",
       " '1524.jpg',\n",
       " '1525.jpg',\n",
       " '1526.jpg',\n",
       " '1527.jpg',\n",
       " '1528.jpg',\n",
       " '1529.jpg',\n",
       " '153.jpg',\n",
       " '1530.jpg',\n",
       " '1531.jpg',\n",
       " '1532.jpg',\n",
       " '1533.jpg',\n",
       " '1534.jpg',\n",
       " '1535.jpg',\n",
       " '1536.jpg',\n",
       " '1537.jpg',\n",
       " '1538.jpg',\n",
       " '1539.jpg',\n",
       " '154.jpg',\n",
       " '1540.jpg',\n",
       " '1541.jpg',\n",
       " '1542.jpg',\n",
       " '1543.jpg',\n",
       " '1544.jpg',\n",
       " '1545.jpg',\n",
       " '1546.jpg',\n",
       " '1547.jpg',\n",
       " '1548.jpg',\n",
       " '1549.jpg',\n",
       " '155.jpg',\n",
       " '1550.jpg',\n",
       " '1551.jpg',\n",
       " '1552.jpg',\n",
       " '1553.jpg',\n",
       " '1554.jpg',\n",
       " '1555.jpg',\n",
       " '1556.jpg',\n",
       " '1557.jpg',\n",
       " '1558.jpg',\n",
       " '1559.jpg',\n",
       " '156.jpg',\n",
       " '1560.jpg',\n",
       " '1561.jpg',\n",
       " '1562.jpg',\n",
       " '1563.jpg',\n",
       " '1564.jpg',\n",
       " '1565.jpg',\n",
       " '1566.jpg',\n",
       " '1567.jpg',\n",
       " '1568.jpg',\n",
       " '1569.jpg',\n",
       " '157.jpg',\n",
       " '1570.jpg',\n",
       " '1571.jpg',\n",
       " '1572.jpg',\n",
       " '1573.jpg',\n",
       " '1574.jpg',\n",
       " '1575.jpg',\n",
       " '1576.jpg',\n",
       " '1577.jpg',\n",
       " '1578.jpg',\n",
       " '1579.jpg',\n",
       " '158.jpg',\n",
       " '1580.jpg',\n",
       " '1581.jpg',\n",
       " '1582.jpg',\n",
       " '1583.jpg',\n",
       " '1584.jpg',\n",
       " '1585.jpg',\n",
       " '1586.jpg',\n",
       " '1587.jpg',\n",
       " '1588.jpg',\n",
       " '1589.jpg',\n",
       " '159.jpg',\n",
       " '1590.jpg',\n",
       " '1591.jpg',\n",
       " '1592.jpg',\n",
       " '1593.jpg',\n",
       " '1594.jpg',\n",
       " '1595.jpg',\n",
       " '1596.jpg',\n",
       " '1597.jpg',\n",
       " '1598.jpg',\n",
       " '1599.jpg',\n",
       " '16.jpg',\n",
       " '160.jpg',\n",
       " '1600.jpg',\n",
       " '1601.jpg',\n",
       " '1602.jpg',\n",
       " '1603.jpg',\n",
       " '1604.jpg',\n",
       " '1605.jpg',\n",
       " '1606.jpg',\n",
       " '1607.jpg',\n",
       " '1608.jpg',\n",
       " '1609.jpg',\n",
       " '161.jpg',\n",
       " '1610.jpg',\n",
       " '1611.jpg',\n",
       " '1612.jpg',\n",
       " '1613.jpg',\n",
       " '1614.jpg',\n",
       " '1615.jpg',\n",
       " '1616.jpg',\n",
       " '1617.jpg',\n",
       " '1618.jpg',\n",
       " '1619.jpg',\n",
       " '162.jpg',\n",
       " '1620.jpg',\n",
       " '1621.jpg',\n",
       " '1622.jpg',\n",
       " '1623.jpg',\n",
       " '1624.jpg',\n",
       " '1625.jpg',\n",
       " '1626.jpg',\n",
       " '1627.jpg',\n",
       " '1628.jpg',\n",
       " '1629.jpg',\n",
       " '163.jpg',\n",
       " '1630.jpg',\n",
       " '1631.jpg',\n",
       " '1632.jpg',\n",
       " '1633.jpg',\n",
       " '1634.jpg',\n",
       " '1635.jpg',\n",
       " '1636.jpg',\n",
       " '1637.jpg',\n",
       " '1638.jpg',\n",
       " '1639.jpg',\n",
       " '164.jpg',\n",
       " '1640.jpg',\n",
       " '1641.jpg',\n",
       " '1642.jpg',\n",
       " '1643.jpg',\n",
       " '1644.jpg',\n",
       " '1645.jpg',\n",
       " '1646.jpg',\n",
       " '1647.jpg',\n",
       " '1648.jpg',\n",
       " '1649.jpg',\n",
       " '165.jpg',\n",
       " '1650.jpg',\n",
       " '1651.jpg',\n",
       " '1652.jpg',\n",
       " '1653.jpg',\n",
       " '1654.jpg',\n",
       " '1655.jpg',\n",
       " '1656.jpg',\n",
       " '1657.jpg',\n",
       " '1658.jpg',\n",
       " '1659.jpg',\n",
       " '166.jpg',\n",
       " '1660.jpg',\n",
       " '1661.jpg',\n",
       " '1662.jpg',\n",
       " '1663.jpg',\n",
       " '1664.jpg',\n",
       " '1665.jpg',\n",
       " '1666.jpg',\n",
       " '1667.jpg',\n",
       " '1668.jpg',\n",
       " '1669.jpg',\n",
       " '167.jpg',\n",
       " '1670.jpg',\n",
       " '1671.jpg',\n",
       " '1672.jpg',\n",
       " '1673.jpg',\n",
       " '1674.jpg',\n",
       " '1675.jpg',\n",
       " '1676.jpg',\n",
       " '1677.jpg',\n",
       " '1678.jpg',\n",
       " '1679.jpg',\n",
       " '168.jpg',\n",
       " '1680.jpg',\n",
       " '1681.jpg',\n",
       " '1682.jpg',\n",
       " '1683.jpg',\n",
       " '1684.jpg',\n",
       " '1685.jpg',\n",
       " '1686.jpg',\n",
       " '1687.jpg',\n",
       " '1688.jpg',\n",
       " '1689.jpg',\n",
       " '169.jpg',\n",
       " '1690.jpg',\n",
       " '1691.jpg',\n",
       " '1692.jpg',\n",
       " '1693.jpg',\n",
       " '1694.jpg',\n",
       " '1695.jpg',\n",
       " '1696.jpg',\n",
       " '1697.jpg',\n",
       " '1698.jpg',\n",
       " '1699.jpg',\n",
       " '17.jpg',\n",
       " '170.jpg',\n",
       " '1700.jpg',\n",
       " '1701.jpg',\n",
       " '1702.jpg',\n",
       " '1703.jpg',\n",
       " '1704.jpg',\n",
       " '1705.jpg',\n",
       " '1706.jpg',\n",
       " '1707.jpg',\n",
       " '1708.jpg',\n",
       " '1709.jpg',\n",
       " '171.jpg',\n",
       " '1710.jpg',\n",
       " '1711.jpg',\n",
       " '1712.jpg',\n",
       " '1713.jpg',\n",
       " '1714.jpg',\n",
       " '1715.jpg',\n",
       " '1716.jpg',\n",
       " '1717.jpg',\n",
       " '1718.jpg',\n",
       " '1719.jpg',\n",
       " '172.jpg',\n",
       " '1720.jpg',\n",
       " '1721.jpg',\n",
       " '1722.jpg',\n",
       " '1723.jpg',\n",
       " '1724.jpg',\n",
       " '1725.jpg',\n",
       " '1726.jpg',\n",
       " '1727.jpg',\n",
       " '1728.jpg',\n",
       " '1729.jpg',\n",
       " '173.jpg',\n",
       " '1730.jpg',\n",
       " '1731.jpg',\n",
       " '1732.jpg',\n",
       " '1733.jpg',\n",
       " '1734.jpg',\n",
       " '1735.jpg',\n",
       " '1736.jpg',\n",
       " '1737.jpg',\n",
       " '1738.jpg',\n",
       " '1739.jpg',\n",
       " '174.jpg',\n",
       " '1740.jpg',\n",
       " '1741.jpg',\n",
       " '1742.jpg',\n",
       " '1743.jpg',\n",
       " '1744.jpg',\n",
       " '1745.jpg',\n",
       " '1746.jpg',\n",
       " '1747.jpg',\n",
       " '1748.jpg',\n",
       " '1749.jpg',\n",
       " '175.jpg',\n",
       " '1750.jpg',\n",
       " '1751.jpg',\n",
       " '1752.jpg',\n",
       " '1753.jpg',\n",
       " '1754.jpg',\n",
       " '1755.jpg',\n",
       " '1756.jpg',\n",
       " '1757.jpg',\n",
       " '1758.jpg',\n",
       " '1759.jpg',\n",
       " '176.jpg',\n",
       " '1760.jpg',\n",
       " '1761.jpg',\n",
       " '1762.jpg',\n",
       " '1763.jpg',\n",
       " '1764.jpg',\n",
       " '1765.jpg',\n",
       " '1766.jpg',\n",
       " '1767.jpg',\n",
       " '1768.jpg',\n",
       " '1769.jpg',\n",
       " '177.jpg',\n",
       " '1770.jpg',\n",
       " '1771.jpg',\n",
       " '1772.jpg',\n",
       " '1773.jpg',\n",
       " '1774.jpg',\n",
       " '1775.jpg',\n",
       " '1776.jpg',\n",
       " '1777.jpg',\n",
       " '1778.jpg',\n",
       " '1779.jpg',\n",
       " '178.jpg',\n",
       " '1780.jpg',\n",
       " '1781.jpg',\n",
       " '1782.jpg',\n",
       " '1783.jpg',\n",
       " '1784.jpg',\n",
       " '1785.jpg',\n",
       " '1786.jpg',\n",
       " '1787.jpg',\n",
       " '1788.jpg',\n",
       " '1789.jpg',\n",
       " '179.jpg',\n",
       " '1790.jpg',\n",
       " '1791.jpg',\n",
       " '1792.jpg',\n",
       " '1793.jpg',\n",
       " '1794.jpg',\n",
       " '1795.jpg',\n",
       " '1796.jpg',\n",
       " '1797.jpg',\n",
       " '1798.jpg',\n",
       " '1799.jpg',\n",
       " '18.jpg',\n",
       " '180.jpg',\n",
       " '1800.jpg',\n",
       " '1801.jpg',\n",
       " '1802.jpg',\n",
       " '1803.jpg',\n",
       " '1804.jpg',\n",
       " '1805.jpg',\n",
       " '1806.jpg',\n",
       " '1807.jpg',\n",
       " '1808.jpg',\n",
       " '1809.jpg',\n",
       " '181.jpg',\n",
       " '1810.jpg',\n",
       " '1811.jpg',\n",
       " '1812.jpg',\n",
       " '1813.jpg',\n",
       " '1814.jpg',\n",
       " '1815.jpg',\n",
       " '1816.jpg',\n",
       " '1817.jpg',\n",
       " '1818.jpg',\n",
       " '1819.jpg',\n",
       " '182.jpg',\n",
       " '1820.jpg',\n",
       " '1821.jpg',\n",
       " '1822.jpg',\n",
       " '1823.jpg',\n",
       " '1824.jpg',\n",
       " '1825.jpg',\n",
       " '1826.jpg',\n",
       " '1827.jpg',\n",
       " '1828.jpg',\n",
       " '1829.jpg',\n",
       " '183.jpg',\n",
       " '1830.jpg',\n",
       " '1831.jpg',\n",
       " '1832.jpg',\n",
       " '1833.jpg',\n",
       " '1834.jpg',\n",
       " '1835.jpg',\n",
       " '1836.jpg',\n",
       " '1837.jpg',\n",
       " '1838.jpg',\n",
       " '1839.jpg',\n",
       " '184.jpg',\n",
       " '1840.jpg',\n",
       " '1841.jpg',\n",
       " '1842.jpg',\n",
       " '1843.jpg',\n",
       " '1844.jpg',\n",
       " '1845.jpg',\n",
       " '1846.jpg',\n",
       " '1847.jpg',\n",
       " '1848.jpg',\n",
       " '1849.jpg',\n",
       " '185.jpg',\n",
       " '1850.jpg',\n",
       " '1851.jpg',\n",
       " '1852.jpg',\n",
       " '1853.jpg',\n",
       " '1854.jpg',\n",
       " '1855.jpg',\n",
       " '1856.jpg',\n",
       " '1857.jpg',\n",
       " '1858.jpg',\n",
       " '1859.jpg',\n",
       " '186.jpg',\n",
       " '1860.jpg',\n",
       " '1861.jpg',\n",
       " '1862.jpg',\n",
       " '1863.jpg',\n",
       " '1864.jpg',\n",
       " '1865.jpg',\n",
       " '1866.jpg',\n",
       " '1867.jpg',\n",
       " '1868.jpg',\n",
       " '1869.jpg',\n",
       " '187.jpg',\n",
       " '1870.jpg',\n",
       " '1871.jpg',\n",
       " '1872.jpg',\n",
       " '1873.jpg',\n",
       " '1874.jpg',\n",
       " '1875.jpg',\n",
       " '1876.jpg',\n",
       " '1877.jpg',\n",
       " '1878.jpg',\n",
       " '1879.jpg',\n",
       " '188.jpg',\n",
       " '1880.jpg',\n",
       " '1881.jpg',\n",
       " '1882.jpg',\n",
       " '1883.jpg',\n",
       " '1884.jpg',\n",
       " '1885.jpg',\n",
       " '1886.jpg',\n",
       " '1887.jpg',\n",
       " '1888.jpg',\n",
       " '1889.jpg',\n",
       " '189.jpg',\n",
       " '1890.jpg',\n",
       " '1891.jpg',\n",
       " '1892.jpg',\n",
       " '1893.jpg',\n",
       " '1894.jpg',\n",
       " '1895.jpg',\n",
       " '1896.jpg',\n",
       " '1897.jpg',\n",
       " '1898.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "## Load training images from the given path based on image names which are there in train data and convert them into array.\n",
    "def load_train_data(img_path):\n",
    "    train_data = [] ## Initialize empty list\n",
    "    for img in tqdm(train['image_names']): ## Get list of image names from train data and process each image name.\n",
    "        if img in image_list: ## If the image name is present in image list then only we have to read image.\n",
    "            path = os.path.join(img_path, img) ## Location of the the image.\n",
    "            img = image.load_img(path,                              ## Load image from the given path and\n",
    "                                 target_size=(64,64,3), ## Keep image size as 28X28X3(height,width,color channels) and\n",
    "                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n",
    "            img = image.img_to_array(img) ## Convert image pixels into an array.\n",
    "            img = img/255 ## Normalize the train data (CNN converg faster on [0..1] data than on [0..255]).\n",
    "            train_data.append(img) ## Add normalized image pixel array to train data.      \n",
    "    return np.array(train_data) ## Convert list into an array and returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1646/1646 [00:01<00:00, 943.80it/s]\n"
     ]
    }
   ],
   "source": [
    "## Get training data for the given image path.\n",
    "train_data = load_train_data(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load testing images from the given path based on images names which are there in test data and convert them into array.\n",
    "def load_test_data(image_path):\n",
    "    test_data = []  ## Initialize empty list\n",
    "    for img in tqdm(test['image_names']): ## Get list of image names from test data and process each image name.\n",
    "        if img in image_list: ## If the image name is present in image list then only we have to read image.\n",
    "            path = os.path.join(image_path, img) ## Location of the the image.\n",
    "            img = image.load_img(path,                              ## Load image from the given path and\n",
    "                                 target_size=(64,64,3), ## Keep image size as 28X28X3(height,width,color channels) and\n",
    "                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n",
    "            img = image.img_to_array(img) ## Convert image pixels into an array.\n",
    "            img = img/255 ## Normalize the test data (CNN converg faster on [0..1] data than on [0..255]).\n",
    "            test_data.append(img) ## Add normalized image pixel array to test data.\n",
    "    return np.array(test_data) ## Convert list into an array and returns it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 706/706 [00:00<00:00, 940.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get testing data for the given image path.\n",
    "test_data = load_test_data(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical ## One hot Encoding.\n",
    "# Do one hot encoding on target/label varible.\n",
    "y = train['emergency_or_not'].values ## Fetch label/target values(0/1).\n",
    "y = to_categorical(y) ## Converts a class vector (integers) to binary class matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the train data into train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,       ## Features(i/p).\n",
    "                                                    y,                ## Traget(0/p).\n",
    "                                                    random_state=101, ## It is the seed used by the random number generator.\n",
    "                                                    test_size=0.2)    ## % of train and validation division.(80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4745098 , 0.49019608, 0.5254902 ],\n",
       "        [0.4392157 , 0.45490196, 0.49019608],\n",
       "        [0.42352942, 0.4392157 , 0.4745098 ],\n",
       "        ...,\n",
       "        [0.68235296, 0.90588236, 0.98039216],\n",
       "        [0.6745098 , 0.9019608 , 0.9882353 ],\n",
       "        [0.6901961 , 0.8862745 , 1.        ]],\n",
       "\n",
       "       [[0.49803922, 0.5254902 , 0.5647059 ],\n",
       "        [0.5176471 , 0.54509807, 0.58431375],\n",
       "        [0.43529412, 0.4627451 , 0.5019608 ],\n",
       "        ...,\n",
       "        [0.69803923, 0.9137255 , 0.99215686],\n",
       "        [0.70980394, 0.9098039 , 0.99215686],\n",
       "        [0.7176471 , 0.8901961 , 0.9882353 ]],\n",
       "\n",
       "       [[0.48235294, 0.5137255 , 0.5568628 ],\n",
       "        [0.5647059 , 0.59607846, 0.6392157 ],\n",
       "        [0.48235294, 0.5137255 , 0.5568628 ],\n",
       "        ...,\n",
       "        [0.76862746, 0.92941177, 1.        ],\n",
       "        [0.7529412 , 0.8980392 , 0.972549  ],\n",
       "        [0.78431374, 0.89411765, 0.98039216]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.12941177, 0.15686275, 0.19607843],\n",
       "        [0.09803922, 0.1254902 , 0.16470589],\n",
       "        [0.1882353 , 0.21568628, 0.25490198],\n",
       "        ...,\n",
       "        [0.59607846, 0.5411765 , 0.5294118 ],\n",
       "        [0.58431375, 0.5294118 , 0.5176471 ],\n",
       "        [0.43137255, 0.3764706 , 0.3647059 ]],\n",
       "\n",
       "       [[0.1254902 , 0.15294118, 0.19215687],\n",
       "        [0.05098039, 0.07843138, 0.11764706],\n",
       "        [0.09411765, 0.12156863, 0.16078432],\n",
       "        ...,\n",
       "        [0.5254902 , 0.47058824, 0.45882353],\n",
       "        [0.38431373, 0.32941177, 0.31764707],\n",
       "        [0.5254902 , 0.47058824, 0.45882353]],\n",
       "\n",
       "       [[0.10980392, 0.13725491, 0.1764706 ],\n",
       "        [0.04705882, 0.07450981, 0.11372549],\n",
       "        [0.11764706, 0.14509805, 0.18431373],\n",
       "        ...,\n",
       "        [0.6431373 , 0.5882353 , 0.5764706 ],\n",
       "        [0.9019608 , 0.84705883, 0.8352941 ],\n",
       "        [0.3529412 , 0.29803923, 0.28627452]]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach : 1 (With Out Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2 - Building the CNN\n",
    "\n",
    "### Initialising the CNN\n",
    "\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "### Step 1 - Convolution\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, \n",
    "                               kernel_size=3, \n",
    "                               activation='relu', \n",
    "                               input_shape=[64, 64, 3]))\n",
    "\n",
    "### Step 2 - Pooling\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "### Adding a second convolutional layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "### Droput 25% Nodes.\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "### Step 3 - Flattening\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "### Step 4 - Full Connection\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "### Step 5 - Output Layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "## Part 3 - Training the CNN\n",
    "\n",
    "### Compiling the CNN\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1316 samples, validate on 330 samples\n",
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1316/1316 [==============================] - 5s 3ms/sample - loss: 0.6004 - acc: 0.6801 - val_loss: 0.4773 - val_acc: 0.7348\n",
      "Epoch 2/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.4616 - acc: 0.7964 - val_loss: 0.4756 - val_acc: 0.7561\n",
      "Epoch 3/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.4152 - acc: 0.8123 - val_loss: 0.4529 - val_acc: 0.7773\n",
      "Epoch 4/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.3792 - acc: 0.8359 - val_loss: 0.4327 - val_acc: 0.7833\n",
      "Epoch 5/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.3194 - acc: 0.8685 - val_loss: 0.4596 - val_acc: 0.7833\n",
      "Epoch 6/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.3124 - acc: 0.8758 - val_loss: 0.4369 - val_acc: 0.7848\n",
      "Epoch 7/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.2576 - acc: 0.8986 - val_loss: 0.4683 - val_acc: 0.8030\n",
      "Epoch 8/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.1974 - acc: 0.9286 - val_loss: 0.4985 - val_acc: 0.8030\n",
      "Epoch 9/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.1701 - acc: 0.9324 - val_loss: 0.4991 - val_acc: 0.7939\n",
      "Epoch 10/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.1257 - acc: 0.9593 - val_loss: 0.7109 - val_acc: 0.7561\n",
      "Epoch 11/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.1352 - acc: 0.9483 - val_loss: 0.4809 - val_acc: 0.8061\n",
      "Epoch 12/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0694 - acc: 0.9852 - val_loss: 0.5562 - val_acc: 0.8061\n",
      "Epoch 13/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0530 - acc: 0.9871 - val_loss: 0.5942 - val_acc: 0.8152\n",
      "Epoch 14/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0369 - acc: 0.9947 - val_loss: 0.6574 - val_acc: 0.8318\n",
      "Epoch 15/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0270 - acc: 0.9962 - val_loss: 0.6124 - val_acc: 0.8091\n",
      "Epoch 16/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0436 - acc: 0.9894 - val_loss: 0.6257 - val_acc: 0.8091\n",
      "Epoch 17/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0449 - acc: 0.9932 - val_loss: 0.6413 - val_acc: 0.7985\n",
      "Epoch 18/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0266 - acc: 0.9951 - val_loss: 0.6842 - val_acc: 0.8106\n",
      "Epoch 19/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0176 - acc: 0.9973 - val_loss: 0.6704 - val_acc: 0.8106\n",
      "Epoch 20/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0260 - acc: 0.9947 - val_loss: 0.7255 - val_acc: 0.8258\n",
      "Epoch 21/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0203 - acc: 0.9954 - val_loss: 0.7414 - val_acc: 0.8182\n",
      "Epoch 22/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0143 - acc: 0.9962 - val_loss: 0.7484 - val_acc: 0.8091\n",
      "Epoch 23/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0135 - acc: 0.9947 - val_loss: 0.8227 - val_acc: 0.7939\n",
      "Epoch 24/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0133 - acc: 0.9958 - val_loss: 1.0641 - val_acc: 0.7864\n",
      "Epoch 25/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0741 - acc: 0.9875 - val_loss: 0.8014 - val_acc: 0.7879\n",
      "Epoch 26/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0472 - acc: 0.9977 - val_loss: 0.8265 - val_acc: 0.8045\n",
      "Epoch 27/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0432 - acc: 0.9970 - val_loss: 0.8825 - val_acc: 0.8000\n",
      "Epoch 28/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0420 - acc: 0.9970 - val_loss: 0.8741 - val_acc: 0.8045\n",
      "Epoch 29/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0425 - acc: 0.9970 - val_loss: 0.9017 - val_acc: 0.7833\n",
      "Epoch 30/30\n",
      "1316/1316 [==============================] - 4s 3ms/sample - loss: 0.0453 - acc: 0.9962 - val_loss: 0.9223 - val_acc: 0.8061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b4e60c7b8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get predictions for test data\n",
    "pred_cnn = cnn.predict_classes(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cnn = pd.read_csv('sample_submission_yxjOnvz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cnn['emergency_or_not'] = pred_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cnn.to_csv('cnn_try.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(loss='categorical_crossentropy',  ## String (name of objective function) or objective function or`Loss` instance.\n",
    "              optimizer='Adam',                 ## String (name of optimizer) or optimizer instance.\n",
    "              metrics=['accuracy'])             ## List of metrics to be evaluated by the model during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach : 2 (With Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2 - Building the CNN\n",
    "\n",
    "### Initialising the CNN\n",
    "\n",
    "cnn1 = tf.keras.models.Sequential()\n",
    "\n",
    "### Step 1 - Convolution\n",
    "\n",
    "cnn1.add(tf.keras.layers.Conv2D(filters=32, \n",
    "                               kernel_size=5,\n",
    "                               padding = 'same',\n",
    "                               activation='relu', \n",
    "                               input_shape=[64, 64, 3]))\n",
    "\n",
    "### Step 2 - Pooling\n",
    "\n",
    "cnn1.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "### Adding a second convolutional layer\n",
    "\n",
    "cnn1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation='relu'))\n",
    "cnn1.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "### Droput 25% Nodes.\n",
    "cnn1.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn1.add(tf.keras.layers.Conv2D(filters=32, \n",
    "                               kernel_size=3,\n",
    "                               padding = 'same',\n",
    "                               activation='relu', \n",
    "                               input_shape=[64, 64, 3]))\n",
    "\n",
    "cnn1.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "### Droput 25% Nodes.\n",
    "cnn1.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "### Step 3 - Flattening\n",
    "\n",
    "cnn1.add(tf.keras.layers.Flatten())\n",
    "\n",
    "### Step 4 - Full Connection\n",
    "\n",
    "cnn1.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "### Step 5 - Output Layer\n",
    "\n",
    "cnn1.add(tf.keras.layers.Dense(units=2, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3 - Training the CNN\n",
    "\n",
    "### Compiling the CNN\n",
    "\n",
    "cnn1.compile(optimizer ='adam',           \n",
    "              loss = \"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,            ## Set input mean to 0 over the dataset\n",
    "                             samplewise_center=False,             ## Set each sample mean to 0\n",
    "                             featurewise_std_normalization=False, ## Divide inputs by std of the dataset\n",
    "                             samplewise_std_normalization=False,  ## Divide each input by its std\n",
    "                             zca_whitening=False,                 ## Apply ZCA whitening\n",
    "                             rotation_range=10,                   ## Randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             zoom_range = 0.1,                    ## Randomly zoom image \n",
    "                             width_shift_range=0.1,               ## Randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.1,              ## Randomly shift images vertically (fraction of total height)\n",
    "                             horizontal_flip=False,               ## Randomly flip images horizontally\n",
    "                             vertical_flip=False)                 ## Randomly flip images vertically\n",
    "\n",
    "## Fit data augmentation model\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.6441 - acc: 0.6879\n",
      " - 7s - loss: 0.6855 - acc: 0.5600 - val_loss: 0.6423 - val_acc: 0.6879\n",
      "Epoch 2/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5976 - acc: 0.7152\n",
      " - 7s - loss: 0.6435 - acc: 0.6505 - val_loss: 0.5995 - val_acc: 0.7152\n",
      "Epoch 3/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5721 - acc: 0.7273\n",
      " - 7s - loss: 0.6514 - acc: 0.6383 - val_loss: 0.5744 - val_acc: 0.7273\n",
      "Epoch 4/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5520 - acc: 0.7424\n",
      " - 7s - loss: 0.5728 - acc: 0.7105 - val_loss: 0.5505 - val_acc: 0.7424\n",
      "Epoch 5/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5665 - acc: 0.7212\n",
      " - 7s - loss: 0.5588 - acc: 0.7371 - val_loss: 0.5732 - val_acc: 0.7212\n",
      "Epoch 6/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5150 - acc: 0.7394\n",
      " - 7s - loss: 0.5368 - acc: 0.7424 - val_loss: 0.5179 - val_acc: 0.7394\n",
      "Epoch 7/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5030 - acc: 0.7576\n",
      " - 7s - loss: 0.5228 - acc: 0.7500 - val_loss: 0.5048 - val_acc: 0.7576\n",
      "Epoch 8/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5323 - acc: 0.7303\n",
      " - 7s - loss: 0.5318 - acc: 0.7447 - val_loss: 0.5360 - val_acc: 0.7303\n",
      "Epoch 9/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5017 - acc: 0.7485\n",
      " - 7s - loss: 0.4977 - acc: 0.7553 - val_loss: 0.5095 - val_acc: 0.7485\n",
      "Epoch 10/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4981 - acc: 0.7515\n",
      " - 7s - loss: 0.4777 - acc: 0.7629 - val_loss: 0.5034 - val_acc: 0.7515\n",
      "Epoch 11/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5015 - acc: 0.7455\n",
      " - 7s - loss: 0.4736 - acc: 0.7614 - val_loss: 0.5101 - val_acc: 0.7455\n",
      "Epoch 12/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4668 - acc: 0.7697\n",
      " - 7s - loss: 0.4645 - acc: 0.7667 - val_loss: 0.4719 - val_acc: 0.7697\n",
      "Epoch 13/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5179 - acc: 0.7182\n",
      " - 7s - loss: 0.5163 - acc: 0.7257 - val_loss: 0.5179 - val_acc: 0.7182\n",
      "Epoch 14/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4893 - acc: 0.7545\n",
      " - 7s - loss: 0.4600 - acc: 0.7698 - val_loss: 0.4945 - val_acc: 0.7545\n",
      "Epoch 15/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4865 - acc: 0.7788\n",
      " - 7s - loss: 0.4471 - acc: 0.7720 - val_loss: 0.4947 - val_acc: 0.7788\n",
      "Epoch 16/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.5034 - acc: 0.7424\n",
      " - 7s - loss: 0.4384 - acc: 0.7705 - val_loss: 0.5112 - val_acc: 0.7424\n",
      "Epoch 17/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4968 - acc: 0.7636\n",
      " - 7s - loss: 0.4529 - acc: 0.7842 - val_loss: 0.5056 - val_acc: 0.7636\n",
      "Epoch 18/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4577 - acc: 0.7697\n",
      " - 7s - loss: 0.4592 - acc: 0.7926 - val_loss: 0.4657 - val_acc: 0.7697\n",
      "Epoch 19/30\n",
      "330/330 [==============================] - 1s 3ms/sample - loss: 0.4734 - acc: 0.7818\n",
      " - 7s - loss: 0.4107 - acc: 0.7979 - val_loss: 0.4858 - val_acc: 0.7818\n",
      "Epoch 20/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4594 - acc: 0.7727\n",
      " - 7s - loss: 0.4284 - acc: 0.7941 - val_loss: 0.4702 - val_acc: 0.7727\n",
      "Epoch 21/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4556 - acc: 0.8061\n",
      " - 7s - loss: 0.4077 - acc: 0.8093 - val_loss: 0.4730 - val_acc: 0.8061\n",
      "Epoch 22/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4557 - acc: 0.8152\n",
      " - 7s - loss: 0.4199 - acc: 0.7918 - val_loss: 0.4634 - val_acc: 0.8152\n",
      "Epoch 23/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4550 - acc: 0.8030\n",
      " - 7s - loss: 0.3899 - acc: 0.8100 - val_loss: 0.4615 - val_acc: 0.8030\n",
      "Epoch 24/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4131 - acc: 0.8152\n",
      " - 7s - loss: 0.4078 - acc: 0.8002 - val_loss: 0.4184 - val_acc: 0.8152\n",
      "Epoch 25/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4523 - acc: 0.7970\n",
      " - 7s - loss: 0.4034 - acc: 0.8009 - val_loss: 0.4583 - val_acc: 0.7970\n",
      "Epoch 26/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4315 - acc: 0.8091\n",
      " - 7s - loss: 0.3887 - acc: 0.8123 - val_loss: 0.4338 - val_acc: 0.8091\n",
      "Epoch 27/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4382 - acc: 0.8030\n",
      " - 7s - loss: 0.3903 - acc: 0.8146 - val_loss: 0.4505 - val_acc: 0.8030\n",
      "Epoch 28/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4836 - acc: 0.7758\n",
      " - 7s - loss: 0.3720 - acc: 0.8207 - val_loss: 0.4979 - val_acc: 0.7758\n",
      "Epoch 29/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4406 - acc: 0.8030\n",
      " - 7s - loss: 0.3817 - acc: 0.8070 - val_loss: 0.4619 - val_acc: 0.8030\n",
      "Epoch 30/30\n",
      "330/330 [==============================] - 1s 2ms/sample - loss: 0.4555 - acc: 0.8000\n",
      " - 7s - loss: 0.3540 - acc: 0.8313 - val_loss: 0.4699 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "history = cnn1.fit_generator(datagen.flow(X_train,                           ## Input data\n",
    "                                           y_train,                           ## Labels/ Target/ out put data\n",
    "                                           batch_size=32),            ## Batch size (default: 32)\n",
    "                              epochs = 30,                                ## Number of epochs to train the model.\n",
    "                              validation_data = (X_test, y_test),             ## On which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data(Validation data).\n",
    "                              verbose = 2,                                    ## 0, 1, or 2. Verbosity mode 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "                              steps_per_epoch=X_train.shape[0] // batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_pred = cnn1.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1_pred = np.argmax(cnn1_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cnn1 = pd.read_csv('sample_submission_yxjOnvz.csv')\n",
    "sub_cnn1['emergency_or_not'] = cnn1_pred\n",
    "sub_cnn1.to_csv('cnn_pred_1.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
